{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade4008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: h:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\notebooks\n",
      "Repo root   : h:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "nb_dir = Path.cwd()\n",
    "repo_root = None\n",
    "for p in [nb_dir] + list(nb_dir.parents):\n",
    "    if (p / \"src\").is_dir():\n",
    "        repo_root = p\n",
    "        break\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(\"Cannot find repo root containing src/\")\n",
    "\n",
    "sys.path.insert(0, str(repo_root))\n",
    "print(\"Notebook dir:\", nb_dir)\n",
    "print(\"Repo root   :\", repo_root)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9370a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_VOL: (4, 150, 200, 200)\n",
      "C_VOL: (150, 200, 200)\n",
      "M_VOL: (150, 200, 200)\n",
      "ilines: [1 2 3] ... [148 149 150]\n",
      "xlines: [1 2 3] ... [198 199 200]\n",
      "dt_ms: 1.0 twt_ms[0:5]: [0. 1. 2. 3. 4.]\n",
      "processed_dir: H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "from src.geo_constraints import DataPaths\n",
    "\n",
    "DATA_ROOT = r\"H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\"\n",
    "paths = DataPaths(DATA_ROOT)\n",
    "\n",
    "constraints_npz = os.path.join(paths.processed_dir, \"constraints.npz\")\n",
    "npz = np.load(constraints_npz, allow_pickle=True)\n",
    "\n",
    "P_VOL = npz[\"P\"].astype(np.float32)       # [4,150,200,200]\n",
    "C_VOL = npz[\"C\"].astype(np.float32)       # [150,200,200]\n",
    "M_VOL = npz[\"M\"].astype(np.float32)       # [150,200,200]\n",
    "ilines = npz[\"ilines\"].astype(int)        # [150]\n",
    "xlines = npz[\"xlines\"].astype(int)        # [200]\n",
    "twt_ms = npz[\"twt_ms\"].astype(np.float32) # [200]\n",
    "dt_ms  = float(npz[\"dt_ms\"])              # scalar\n",
    "\n",
    "print(\"P_VOL:\", P_VOL.shape)\n",
    "print(\"C_VOL:\", C_VOL.shape)\n",
    "print(\"M_VOL:\", M_VOL.shape)\n",
    "print(\"ilines:\", ilines[:3], \"...\", ilines[-3:])\n",
    "print(\"xlines:\", xlines[:3], \"...\", xlines[-3:])\n",
    "print(\"dt_ms:\", dt_ms, \"twt_ms[0:5]:\", twt_ms[:5])\n",
    "print(\"processed_dir:\", paths.processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c875cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cube: (150, 200, 200) missing traces: 0\n",
      "SEIS min/max: 4.318020820617676 9.578778266906738\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import segyio\n",
    "import numpy as np\n",
    "\n",
    "SEIS_SGY = r\"H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\ATTR_TIME_SGY\\AI_FINAL_IL2_XL1_S0_XY25.sgy\"\n",
    "assert os.path.isfile(SEIS_SGY), SEIS_SGY\n",
    "\n",
    "def read_segy_cube_ilxl_t(path, ilines, xlines, T_expected=200):\n",
    "    \"\"\"\n",
    "    Read SEG-Y into cube [IL,XL,T] using segyio.\n",
    "    Assumes file contains traces for all IL×XL.\n",
    "    \"\"\"\n",
    "    with segyio.open(path, \"r\", ignore_geometry=False) as f:\n",
    "        f.mmap()\n",
    "        samples = np.array(f.samples, dtype=np.float32)\n",
    "        T = len(samples)\n",
    "        assert T == T_expected, f\"T mismatch: segy T={T}, expected {T_expected}\"\n",
    "\n",
    "        # map from (il,xl) -> trace index\n",
    "        # segyio gives us attributes via f.attributes\n",
    "        ils = f.attributes(segyio.TraceField.INLINE_3D)[:]\n",
    "        xls = f.attributes(segyio.TraceField.CROSSLINE_3D)[:]\n",
    "\n",
    "        idx_map = {}\n",
    "        for tr in range(f.tracecount):\n",
    "            idx_map[(int(ils[tr]), int(xls[tr]))] = tr\n",
    "\n",
    "        ILn = len(ilines); XLn = len(xlines)\n",
    "        cube = np.zeros((ILn, XLn, T), dtype=np.float32)\n",
    "\n",
    "        missing = 0\n",
    "        for i, il in enumerate(ilines):\n",
    "            for j, xl in enumerate(xlines):\n",
    "                tr = idx_map.get((int(il), int(xl)), None)\n",
    "                if tr is None:\n",
    "                    missing += 1\n",
    "                    continue\n",
    "                cube[i, j, :] = f.trace[tr].astype(np.float32)\n",
    "\n",
    "        print(\"Loaded cube:\", cube.shape, \"missing traces:\", missing)\n",
    "        return cube, samples\n",
    "\n",
    "SEIS, seis_samples = read_segy_cube_ilxl_t(SEIS_SGY, ilines, xlines, T_expected=200)\n",
    "print(\"SEIS min/max:\", float(SEIS.min()), float(SEIS.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df88635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\checkpoints_multitask_final\\best_joint.pt\n",
      "Model loaded.\n",
      "AI mean/std: 7.208985805511475 1.2618153095245361\n",
      "Seis mean/std: 7.208985805511475 1.2618153095245361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_31144\\3551611423.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "from src.models.geo_cnn_multitask import GeoCNNMultiTask\n",
    "from src.dataset_vie import StanfordVIEWellPatchDataset\n",
    "\n",
    "# 用 dataset 只拿 mean/std（必须与训练一致）\n",
    "ds = StanfordVIEWellPatchDataset(paths, constraints_npz, patch_hw=4, use_masked_y=True, normalize=True)\n",
    "\n",
    "ckpt_dir = os.path.join(paths.processed_dir, \"checkpoints_multitask_final\")\n",
    "ckpt_path = os.path.join(ckpt_dir, \"best_joint.pt\")  # or best_ai.pt\n",
    "assert os.path.isfile(ckpt_path), ckpt_path\n",
    "print(\"ckpt:\", ckpt_path)\n",
    "\n",
    "def build_model():\n",
    "    return GeoCNNMultiTask(in_channels=7, base=32, t=200, n_facies=4).to(device)\n",
    "\n",
    "def load_ckpt(model, ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    state = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    model.eval()\n",
    "\n",
    "def unpack_outputs(out):\n",
    "    ai_pred = None\n",
    "    facies_logits = None\n",
    "    if isinstance(out, dict):\n",
    "        for k in [\"ai\", \"ai_pred\", \"y\", \"imp\", \"impedance\"]:\n",
    "            if k in out:\n",
    "                ai_pred = out[k]; break\n",
    "        for k in [\"facies\", \"facies_logits\", \"logits\", \"facies_logit\"]:\n",
    "            if k in out:\n",
    "                facies_logits = out[k]; break\n",
    "    elif isinstance(out, (list, tuple)):\n",
    "        ai_pred = out[0]\n",
    "        facies_logits = out[1] if len(out) > 1 else None\n",
    "    else:\n",
    "        ai_pred = out\n",
    "    return ai_pred, facies_logits\n",
    "\n",
    "model = build_model()\n",
    "load_ckpt(model, ckpt_path)\n",
    "\n",
    "print(\"Model loaded.\")\n",
    "print(\"AI mean/std:\", ds.ai_mean, ds.ai_std)\n",
    "print(\"Seis mean/std:\", ds.seis_mean, ds.seis_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83218fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEIS_N min/max: -2.2911157608032227 1.8780819177627563\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "SEIS_N = (SEIS - float(ds.seis_mean)) / (float(ds.seis_std) + 1e-12)\n",
    "print(\"SEIS_N min/max:\", float(SEIS_N.min()), float(SEIS_N.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034f9351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total traces: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_31144\\567717713.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp_ctx(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3200/30000 done\n",
      "  6400/30000 done\n",
      "  9600/30000 done\n",
      "  12800/30000 done\n",
      "  16000/30000 done\n",
      "  19200/30000 done\n",
      "  22400/30000 done\n",
      "  25600/30000 done\n",
      "  28800/30000 done\n",
      "Inference done: (150, 200, 200) (150, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "patch_hw = 4\n",
    "H = W = 2*patch_hw + 1\n",
    "IL, XL, T = SEIS_N.shape\n",
    "assert (IL,XL,T) == (150,200,200)\n",
    "\n",
    "AI_pred_cube = np.empty((IL, XL, T), dtype=np.float32)\n",
    "Facies_pred_cube = np.full((IL, XL, T), -1, dtype=np.int16)\n",
    "\n",
    "batch_size = 64  # ✅ 你可以尝试 64/128，显存不够就降回32/16\n",
    "print(\"Total traces:\", IL*XL)\n",
    "\n",
    "# =========================\n",
    "# 1) 只 pad 一次（巨大提速点）\n",
    "# =========================\n",
    "pad = patch_hw\n",
    "\n",
    "SEIS_pad = np.pad(SEIS_N, ((pad,pad),(pad,pad),(0,0)), mode=\"edge\")   # [IL+2p, XL+2p, T]\n",
    "C_pad    = np.pad(C_VOL,  ((pad,pad),(pad,pad),(0,0)), mode=\"edge\")   # [IL+2p, XL+2p, T]\n",
    "M_pad    = np.pad(M_VOL,  ((pad,pad),(pad,pad),(0,0)), mode=\"edge\")   # [IL+2p, XL+2p, T]\n",
    "P_pad    = np.pad(P_VOL,  ((0,0),(pad,pad),(pad,pad),(0,0)), mode=\"edge\")  # [4, IL+2p, XL+2p, T]\n",
    "\n",
    "# =========================\n",
    "# 2) 预分配 batch numpy\n",
    "# =========================\n",
    "x_batch = np.empty((batch_size, 1, H, W, T), dtype=np.float32)\n",
    "p_batch = np.empty((batch_size, 4, H, W, T), dtype=np.float32)\n",
    "c_batch = np.empty((batch_size, 1, H, W, T), dtype=np.float32)\n",
    "m_batch = np.empty((batch_size, 1, H, W, T), dtype=np.float32)\n",
    "\n",
    "# autocast：GPU 上可进一步加速（不影响输出类型，我们最终还是 denorm 到 float32）\n",
    "use_amp = (device.type == \"cuda\")\n",
    "amp_ctx = torch.cuda.amp.autocast if use_amp else torch.cpu.amp.autocast  # cpu 上基本无意义，但保持结构\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_full_infer_fast():\n",
    "    b = 0   # batch counter\n",
    "    done = 0\n",
    "\n",
    "    # 逐 IL 扫描，cache 更友好\n",
    "    for il in range(IL):\n",
    "        ilp = il  # 在 pad 后数组里，原 il 对应起始就是 il（因为前面 pad 了 pad 个）\n",
    "        for xl in range(XL):\n",
    "            xlp = xl\n",
    "\n",
    "            # 取 patch：pad数组里直接切片\n",
    "            # SEIS_pad: [IL+2p, XL+2p, T] -> patch [H,W,T]\n",
    "            x_patch = SEIS_pad[ilp:ilp+H, xlp:xlp+W, :]\n",
    "            c_patch = C_pad[ilp:ilp+H, xlp:xlp+W, :]\n",
    "            m_patch = M_pad[ilp:ilp+H, xlp:xlp+W, :]\n",
    "            p_patch = P_pad[:, ilp:ilp+H, xlp:xlp+W, :]\n",
    "\n",
    "            # 填入 batch buffer（避免 list + stack）\n",
    "            x_batch[b, 0] = x_patch\n",
    "            p_batch[b]    = p_patch\n",
    "            c_batch[b, 0] = c_patch\n",
    "            m_batch[b, 0] = m_patch\n",
    "\n",
    "            b += 1\n",
    "\n",
    "            # 满 batch 或者最后一个点，执行推理\n",
    "            if b == batch_size or (il == IL-1 and xl == XL-1):\n",
    "                xb = torch.from_numpy(x_batch[:b]).to(device, non_blocking=True)\n",
    "                pb = torch.from_numpy(p_batch[:b]).to(device, non_blocking=True)\n",
    "                cb = torch.from_numpy(c_batch[:b]).to(device, non_blocking=True)\n",
    "                mb = torch.from_numpy(m_batch[:b]).to(device, non_blocking=True)\n",
    "\n",
    "                with amp_ctx(enabled=use_amp):\n",
    "                    out = model(xb, pb, cb, mb)\n",
    "\n",
    "                ai_pred, facies_logits = unpack_outputs(out)\n",
    "\n",
    "                # ai_pred -> [b,T]\n",
    "                ai_pred = ai_pred.squeeze()\n",
    "                if ai_pred.ndim == 1:\n",
    "                    ai_pred = ai_pred[None, :]\n",
    "                if ai_pred.ndim != 2:\n",
    "                    ai_pred = ai_pred.reshape(ai_pred.shape[0], -1)\n",
    "\n",
    "                ai_den = ai_pred.detach().float().cpu().numpy().astype(np.float32) * float(ds.ai_std) + float(ds.ai_mean)\n",
    "\n",
    "                # facies：用 torch argmax，最后转 numpy\n",
    "                fac_pred = None\n",
    "                if facies_logits is not None:\n",
    "                    L = facies_logits.detach()\n",
    "                    # squeeze 多余 1 维\n",
    "                    while L.dim() > 2 and 1 in L.shape:\n",
    "                        L = L.squeeze()\n",
    "                    # 统一到 [B,4,T]\n",
    "                    if L.dim() == 2:\n",
    "                        if L.shape[0] == 4:\n",
    "                            L = L.unsqueeze(0)\n",
    "                        elif L.shape[1] == 4:\n",
    "                            L = L.transpose(0,1).unsqueeze(0)\n",
    "                        else:\n",
    "                            raise RuntimeError(f\"Unexpected facies logits shape (2D): {tuple(L.shape)}\")\n",
    "                    elif L.dim() == 3:\n",
    "                        if L.shape[1] == 4:\n",
    "                            pass\n",
    "                        elif L.shape[2] == 4:\n",
    "                            L = L.transpose(1,2)\n",
    "                        else:\n",
    "                            raise RuntimeError(f\"Unexpected facies logits shape (3D): {tuple(L.shape)}\")\n",
    "                    else:\n",
    "                        raise RuntimeError(f\"Unexpected facies logits dim: {L.dim()} shape={tuple(L.shape)}\")\n",
    "\n",
    "                    fac_pred = torch.argmax(L, dim=1).cpu().numpy().astype(np.int16)  # [b,T]\n",
    "\n",
    "                # 写回 cube：需要知道这 b 个样本对应的 (il,xl)\n",
    "                # 我们按扫描顺序写回：done 是全局 trace index\n",
    "                for k in range(b):\n",
    "                    g = done + k\n",
    "                    i = g // XL\n",
    "                    j = g % XL\n",
    "                    AI_pred_cube[i, j, :] = ai_den[k]\n",
    "                    if fac_pred is not None:\n",
    "                        Facies_pred_cube[i, j, :] = fac_pred[k]\n",
    "\n",
    "                done += b\n",
    "                if (done // batch_size) % 50 == 0:\n",
    "                    print(f\"  {done}/{IL*XL} done\")\n",
    "\n",
    "                b = 0  # reset batch counter\n",
    "\n",
    "run_full_infer_fast()\n",
    "print(\"Inference done:\", AI_pred_cube.shape, Facies_pred_cube.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d60a955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved npy: H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\AI_pred_cube.npy\n",
      "Saved npy: H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\Facies_pred_cube.npy\n",
      "Saved segy:\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\AI_pred_cube.segy\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\Facies_pred_cube.segy\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "OUT_DIR = os.path.join(paths.processed_dir, \"inversion_volume_fullcube\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "ai_pred_npy  = os.path.join(OUT_DIR, \"AI_pred_cube.npy\")\n",
    "fac_pred_npy = os.path.join(OUT_DIR, \"Facies_pred_cube.npy\")\n",
    "np.save(ai_pred_npy, AI_pred_cube)\n",
    "np.save(fac_pred_npy, Facies_pred_cube)\n",
    "print(\"Saved npy:\", ai_pred_npy)\n",
    "print(\"Saved npy:\", fac_pred_npy)\n",
    "\n",
    "def write_segy_cube(filepath, cube, ilines, xlines, twt_ms):\n",
    "    import segyio\n",
    "    ILn, XLn, Tn = cube.shape\n",
    "    spec = segyio.spec()\n",
    "    spec.sorting = 2\n",
    "    spec.format = 5\n",
    "    spec.ilines = ilines.tolist()\n",
    "    spec.xlines = xlines.tolist()\n",
    "    spec.samples = twt_ms.astype(np.float32).tolist()\n",
    "\n",
    "    with segyio.create(filepath, spec) as f:\n",
    "        tr = 0\n",
    "        for i, il in enumerate(ilines):\n",
    "            for j, xl in enumerate(xlines):\n",
    "                trace = cube[i, j, :].astype(np.float32)\n",
    "                trace = np.nan_to_num(trace, nan=0.0)\n",
    "                f.trace[tr] = trace\n",
    "                f.header[tr][segyio.TraceField.INLINE_3D] = int(il)\n",
    "                f.header[tr][segyio.TraceField.CROSSLINE_3D] = int(xl)\n",
    "                tr += 1\n",
    "        f.flush()\n",
    "\n",
    "ai_pred_segy  = os.path.join(OUT_DIR, \"AI_pred_cube.segy\")\n",
    "fac_pred_segy = os.path.join(OUT_DIR, \"Facies_pred_cube.segy\")\n",
    "\n",
    "write_segy_cube(ai_pred_segy, AI_pred_cube, ilines, xlines, twt_ms)\n",
    "write_segy_cube(fac_pred_segy, Facies_pred_cube.astype(np.float32), ilines, xlines, twt_ms)\n",
    "\n",
    "print(\"Saved segy:\")\n",
    "print(\" \", ai_pred_segy)\n",
    "print(\" \", fac_pred_segy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff92931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cube: (150, 200, 200) missing traces: 0\n",
      "AI_TRUE: (150, 200, 200) min/max: 4.318020820617676 9.578778266906738\n",
      "AI_PRED: (150, 200, 200) min/max: 4.1333112716674805 9.656217575073242\n",
      "FIG_DIR: H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\n",
      "\n",
      "Saved figs:\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\\timeslice_40ms_true_pred_diff.png\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\\timeslice_100ms_true_pred_diff.png\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\\timeslice_160ms_true_pred_diff.png\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\\inline_100_true_pred_diff.png\n",
      "  H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\processed\\inversion_volume_fullcube\\figs\\xline_50_true_pred_diff.png\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 0) Input paths ----------\n",
    "AI_TRUE_SGY = r\"H:\\GK-MRL-PhysicsConsistent-Inversion\\GK-MRL-PhysicsConsistent-Inversion\\data\\ATTR_TIME_SGY\\Acoustic_Impedance_TIME_dt1ms_XY25.sgy\"\n",
    "assert os.path.isfile(AI_TRUE_SGY), AI_TRUE_SGY\n",
    "\n",
    "# ---------- 1) Read true cube ----------\n",
    "AI_TRUE, _ = read_segy_cube_ilxl_t(AI_TRUE_SGY, ilines, xlines, T_expected=200)\n",
    "print(\"AI_TRUE:\", AI_TRUE.shape, \"min/max:\", float(AI_TRUE.min()), float(AI_TRUE.max()))\n",
    "print(\"AI_PRED:\", AI_pred_cube.shape, \"min/max:\", float(np.nanmin(AI_pred_cube)), float(np.nanmax(AI_pred_cube)))\n",
    "\n",
    "# ---------- 2) Output dir ----------\n",
    "FIG_DIR = Path(OUT_DIR) / \"figs\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"FIG_DIR:\", FIG_DIR)\n",
    "\n",
    "# ---------- 3) Helpers ----------\n",
    "def ms_to_k(ms):\n",
    "    # twt_ms: [T]\n",
    "    return int(np.argmin(np.abs(twt_ms - ms)))\n",
    "\n",
    "def plot_3panel(\n",
    "    A_true,\n",
    "    A_pred,\n",
    "    title,\n",
    "    fp,\n",
    "    cmap_ai=\"viridis\",\n",
    "    cmap_diff=\"coolwarm\",\n",
    "    p_low=2,\n",
    "    p_high=98,\n",
    "    p_diff=98,\n",
    "    diff_vmax=5,      # ✅ 手动控制 Diff 色标：None=自动；数值=固定±diff_vmax\n",
    "):\n",
    "    \"\"\"\n",
    "    diff_vmax:\n",
    "        None  -> 使用自动百分位 (±p_diff)\n",
    "        float -> 使用固定对称色标 [-diff_vmax, +diff_vmax]\n",
    "    \"\"\"\n",
    "\n",
    "    A_true = np.asarray(A_true, dtype=np.float32)\n",
    "    A_pred = np.asarray(A_pred, dtype=np.float32)\n",
    "    diff = A_pred - A_true\n",
    "\n",
    "    # ---- True / Pred 色标（来自 True 的 robust percentile）----\n",
    "    vmin = float(np.nanpercentile(A_true, p_low))\n",
    "    vmax = float(np.nanpercentile(A_true, p_high))\n",
    "\n",
    "    # ---- Diff 色标 ----\n",
    "    if diff_vmax is None:\n",
    "        dmax = float(np.nanpercentile(np.abs(diff), p_diff))\n",
    "    else:\n",
    "        dmax = float(diff_vmax)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4), constrained_layout=True)\n",
    "\n",
    "    # ---- True ----\n",
    "    im0 = axes[0].imshow(A_true, aspect=\"auto\", vmin=vmin, vmax=vmax, cmap=cmap_ai)\n",
    "    axes[0].set_title(\"True\")\n",
    "    axes[0].set_xlabel(\"XL\")\n",
    "    axes[0].set_ylabel(\"IL / Time\")\n",
    "    c0 = fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    c0.set_label(\"AI\")\n",
    "\n",
    "    # ---- Pred（与 True 同 vmin/vmax）----\n",
    "    im1 = axes[1].imshow(A_pred, aspect=\"auto\", vmin=vmin, vmax=vmax, cmap=cmap_ai)\n",
    "    axes[1].set_title(\"Pred\")\n",
    "    axes[1].set_xlabel(\"XL\")\n",
    "    axes[1].set_ylabel(\"IL / Time\")\n",
    "    c1 = fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    c1.set_label(\"AI\")\n",
    "\n",
    "    # ---- Diff（对称色标）----\n",
    "    im2 = axes[2].imshow(diff, aspect=\"auto\", vmin=-dmax, vmax=dmax, cmap=cmap_diff)\n",
    "    axes[2].set_title(\"Diff (Pred − True)\")\n",
    "    axes[2].set_xlabel(\"XL\")\n",
    "    axes[2].set_ylabel(\"IL / Time\")\n",
    "    c2 = fig.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "    c2.set_label(\"ΔAI\")\n",
    "\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    fig.savefig(fp, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- 4) Make figures ----------\n",
    "saved = []\n",
    "\n",
    "# ✅ 你可以在这里统一设置 Diff 的固定范围（比如 2000 / 3000）\n",
    "# diff_fixed = 2000\n",
    "diff_fixed = 5   # None=自动百分位；改成数值=固定±diff_fixed\n",
    "\n",
    "# (A) Time slices @ 40/100/160 ms\n",
    "for ms in [40, 100, 160]:\n",
    "    k = ms_to_k(ms)\n",
    "    fp = FIG_DIR / f\"timeslice_{ms}ms_true_pred_diff.png\"\n",
    "    plot_3panel(\n",
    "        AI_TRUE[:, :, k],\n",
    "        AI_pred_cube[:, :, k],\n",
    "        title=f\"AI @ {ms} ms\",\n",
    "        fp=str(fp),\n",
    "        cmap_ai=\"viridis\",\n",
    "        cmap_diff=\"coolwarm\",      # 你想用 coolwarm 就保留；也可用 seismic\n",
    "        diff_vmax=diff_fixed\n",
    "    )\n",
    "    saved.append(str(fp))\n",
    "\n",
    "# (B) Inline = 100\n",
    "inline_val = 100\n",
    "ii = int(np.where(ilines == inline_val)[0][0])\n",
    "fp = FIG_DIR / f\"inline_{inline_val}_true_pred_diff.png\"\n",
    "plot_3panel(\n",
    "    AI_TRUE[ii, :, :].T,\n",
    "    AI_pred_cube[ii, :, :].T,\n",
    "    title=f\"Inline {inline_val}\",\n",
    "    fp=str(fp),\n",
    "    cmap_ai=\"viridis\",\n",
    "    cmap_diff=\"seismic\",\n",
    "    diff_vmax=diff_fixed\n",
    ")\n",
    "saved.append(str(fp))\n",
    "\n",
    "# (C) Xline = 50\n",
    "xline_val = 50\n",
    "jj = int(np.where(xlines == xline_val)[0][0])\n",
    "fp = FIG_DIR / f\"xline_{xline_val}_true_pred_diff.png\"\n",
    "plot_3panel(\n",
    "    AI_TRUE[:, jj, :].T,\n",
    "    AI_pred_cube[:, jj, :].T,\n",
    "    title=f\"Xline {xline_val}\",\n",
    "    fp=str(fp),\n",
    "    cmap_ai=\"viridis\",\n",
    "    cmap_diff=\"seismic\",\n",
    "    diff_vmax=diff_fixed\n",
    ")\n",
    "saved.append(str(fp))\n",
    "\n",
    "print(\"\\nSaved figs:\")\n",
    "for p in saved:\n",
    "    print(\" \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c281d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_inv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
